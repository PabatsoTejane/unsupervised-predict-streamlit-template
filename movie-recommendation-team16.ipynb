{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Team 16 - EDSA movie recommendation wilderness**","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\nfrom IPython.core.display import HTML\nImage(url= \"https://storage.googleapis.com/kaggle-competitions/kaggle/33594/logos/header.png?t=2022-01-04-10-31-44\")","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:08:19.581341Z","iopub.execute_input":"2022-02-03T21:08:19.581940Z","iopub.status.idle":"2022-02-03T21:08:19.611979Z","shell.execute_reply.started":"2022-02-03T21:08:19.581847Z","shell.execute_reply":"2022-02-03T21:08:19.611284Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/html":"<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/33594/logos/header.png?t=2022-01-04-10-31-44\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Introduction**\n\nIn today’s technologically-driven society where content creation and the availability of media is booming, we are bombarded with heaps of information on a daily basis. The information becomes very overwhelming to process and creates a choice overload, which makes it more difficult to make decisions, even something as simple as choosing a movie to watch. Spending hours scrolling through a site trying to figure out what movie to watch is definitely a tedious task.\n\nSo... \"What to watch???\"\n\nWell, this is where movie recommender systems come in. Movie recommender sysytems help filter through the thousands of movies and suggest the ones that you have a higher probability to like. This is done through contend and collaborative based filtering, which are the most commonly used methods.","metadata":{}},{"cell_type":"markdown","source":"#### Installations","metadata":{}},{"cell_type":"code","source":"!pip install scikit-plot","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:52:54.266107Z","iopub.execute_input":"2022-02-03T20:52:54.266554Z","iopub.status.idle":"2022-02-03T20:53:25.073132Z","shell.execute_reply.started":"2022-02-03T20:52:54.266517Z","shell.execute_reply":"2022-02-03T20:53:25.071849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Start Comet Experiment","metadata":{}},{"cell_type":"code","source":"#Uncomment the below to create/start a new experiment on Comet\n\n\"\"\"# Start Comet Experiment\nfrom comet_ml import Experiment\n\n# Create an experiment with your api key\nexperiment = Experiment(\n    api_key=\"0PXFIXjRITl64S9L8bH64cfYP\",\n    project_name=\"unsupervised-learning-predict\",\n    workspace=\"henriedwards\",\n)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:25.074931Z","iopub.execute_input":"2022-02-03T20:53:25.075412Z","iopub.status.idle":"2022-02-03T20:53:25.083139Z","shell.execute_reply.started":"2022-02-03T20:53:25.075268Z","shell.execute_reply":"2022-02-03T20:53:25.082484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cont\"></a>\n\n### Table of Contents\n\n<a href=#one>1. Problem Statement</a>\n\n<a href=#two>2. Importing Libraries</a>\n\n<a href=#three>3. Loading Data</a>\n\n<a href=#four>4. Data Preprocessing</a>\n\n<a href=#five>5. Exploratory Data Analysis</a>\n\n<a href=#six>6. Content Based Filtering</a>\n\n<a href=#sevem>7. Collaborative Filtering</a>\n\n<a href=#eight>8. Model Evaluation</a>\n\n<a href=#nine>9. Hyperparameter Tuning</a>\n\n<a href=#ten>10. Conclusion</a>\n\n<a href=#eleven>11. Submission</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"one\"></a>\n## 1. Problem Statement\n\nWe are tasked to construct a recommendation algorithm, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences. To achieve this, we will contruct both a Content-Based filtering & Collaborative Filtering Recommender Systems.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"two\"></a>\n## 2. Importing Libraries","metadata":{}},{"cell_type":"code","source":"# Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Kaggle requirements\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Data analysis libraries\nimport pandas as pd\nimport numpy as np        \n        \n# ML Pre processing\nimport re\nimport time\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nfrom numpy.random import RandomState\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Visualisation libraries\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom plotly.offline import init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n%matplotlib inline\nimport wordcloud\nfrom wordcloud import WordCloud, STOPWORDS\n%matplotlib inline\nsns.set()\nfrom PIL import Image\nfrom nltk.corpus import stopwords\n\n# Content Filtering Models\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Suprise\nfrom surprise import Reader\nfrom surprise import Dataset\nfrom surprise.model_selection import train_test_split\n\n# Collaborative Filtering\nfrom surprise import KNNBasic\nfrom surprise import KNNWithMeans\nfrom surprise import KNNWithZScore\nfrom surprise import KNNBaseline\nfrom surprise import SVD\nfrom surprise import BaselineOnly\nfrom surprise import SVDpp\nfrom surprise import NMF\nfrom surprise import SlopeOne\nfrom surprise import CoClustering\n\n# Evaluation\nfrom surprise.model_selection import cross_validate\nfrom surprise import NormalPredictor\nfrom surprise.accuracy import rmse\nfrom surprise import accuracy\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Hyperparameter tuning\nfrom surprise.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:25.085474Z","iopub.execute_input":"2022-02-03T20:53:25.085709Z","iopub.status.idle":"2022-02-03T20:53:27.444094Z","shell.execute_reply.started":"2022-02-03T20:53:25.085678Z","shell.execute_reply":"2022-02-03T20:53:27.443237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"three\"></a>\n## 3. Loading Data","metadata":{}},{"cell_type":"code","source":"movies = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/movies.csv\")\nmovies_og = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/movies.csv\")\nimdb_data = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/imdb_data.csv\")\ngenome_tags = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/genome_tags.csv\")\ngenome_scores = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/genome_scores.csv\")\ntags = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/tags.csv\")\nlinks = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/links.csv\")\ntrain_data = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:27.445324Z","iopub.execute_input":"2022-02-03T20:53:27.445689Z","iopub.status.idle":"2022-02-03T20:53:47.784530Z","shell.execute_reply.started":"2022-02-03T20:53:27.445651Z","shell.execute_reply":"2022-02-03T20:53:47.783127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"four\"></a>\n## 4. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Data preview**","metadata":{}},{"cell_type":"code","source":"movies.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:47.786226Z","iopub.execute_input":"2022-02-03T20:53:47.786584Z","iopub.status.idle":"2022-02-03T20:53:47.803821Z","shell.execute_reply.started":"2022-02-03T20:53:47.786534Z","shell.execute_reply":"2022-02-03T20:53:47.803135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imdb_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:47.804962Z","iopub.execute_input":"2022-02-03T20:53:47.805316Z","iopub.status.idle":"2022-02-03T20:53:47.818039Z","shell.execute_reply.started":"2022-02-03T20:53:47.805287Z","shell.execute_reply":"2022-02-03T20:53:47.816991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"genome_tags.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:47.819251Z","iopub.execute_input":"2022-02-03T20:53:47.819471Z","iopub.status.idle":"2022-02-03T20:53:47.837625Z","shell.execute_reply.started":"2022-02-03T20:53:47.819444Z","shell.execute_reply":"2022-02-03T20:53:47.836576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"genome_scores.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:47.840791Z","iopub.execute_input":"2022-02-03T20:53:47.841074Z","iopub.status.idle":"2022-02-03T20:53:47.857122Z","shell.execute_reply.started":"2022-02-03T20:53:47.841033Z","shell.execute_reply":"2022-02-03T20:53:47.856175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:47.860785Z","iopub.execute_input":"2022-02-03T20:53:47.861075Z","iopub.status.idle":"2022-02-03T20:53:47.872424Z","shell.execute_reply.started":"2022-02-03T20:53:47.861037Z","shell.execute_reply":"2022-02-03T20:53:47.871369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"links.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:47.874096Z","iopub.execute_input":"2022-02-03T20:53:47.874419Z","iopub.status.idle":"2022-02-03T20:53:47.891764Z","shell.execute_reply.started":"2022-02-03T20:53:47.874372Z","shell.execute_reply":"2022-02-03T20:53:47.890609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:47.893627Z","iopub.execute_input":"2022-02-03T20:53:47.894096Z","iopub.status.idle":"2022-02-03T20:53:47.909532Z","shell.execute_reply.started":"2022-02-03T20:53:47.894045Z","shell.execute_reply":"2022-02-03T20:53:47.908209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check duplicates\ndup_bool = train_data.duplicated(['userId', 'movieId', 'rating', 'timestamp'])\n\n# display duplicates\nprint(\"Number of duplicate records:\", sum(dup_bool))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:47.911833Z","iopub.execute_input":"2022-02-03T20:53:47.912184Z","iopub.status.idle":"2022-02-03T20:53:54.429168Z","shell.execute_reply.started":"2022-02-03T20:53:47.912136Z","shell.execute_reply":"2022-02-03T20:53:54.428092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill NaN values with usable nulls\n\nimdb_data['director'] = imdb_data['director'].fillna('')\nimdb_data['runtime'] = imdb_data['runtime'].fillna('')\nimdb_data['budget'] = imdb_data['budget'].fillna('')\nimdb_data['title_cast'] = imdb_data['title_cast'].fillna('')\nimdb_data['plot_keywords'] = imdb_data['plot_keywords'].fillna('')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:54.430351Z","iopub.execute_input":"2022-02-03T20:53:54.430569Z","iopub.status.idle":"2022-02-03T20:53:54.460827Z","shell.execute_reply.started":"2022-02-03T20:53:54.430537Z","shell.execute_reply":"2022-02-03T20:53:54.459948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove string seperators and add to a list\n\nimdb_data['plot_keywords'] = imdb_data['plot_keywords'].str.split('|')\nimdb_data['title_cast'] = imdb_data['title_cast'].str.split('|')\nmovies['genres'] = movies['genres'].str.split('|')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:54.462457Z","iopub.execute_input":"2022-02-03T20:53:54.462851Z","iopub.status.idle":"2022-02-03T20:53:54.903130Z","shell.execute_reply.started":"2022-02-03T20:53:54.462803Z","shell.execute_reply":"2022-02-03T20:53:54.902093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract year from title into own feature\n\nmovies['year'] = movies['title'].str.extract('(\\d{4})')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:54.904473Z","iopub.execute_input":"2022-02-03T20:53:54.904746Z","iopub.status.idle":"2022-02-03T20:53:55.108036Z","shell.execute_reply.started":"2022-02-03T20:53:54.904713Z","shell.execute_reply":"2022-02-03T20:53:55.106735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def year_remover(text):\n    \n    \"\"\"Function that takes in a string, and removes the year in parenthesis\"\"\"\n    \n    text = re.sub(r'\\([^)]*\\)','',text)\n    return text\n\nmovies['title'] = movies['title'].map(year_remover)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:55.110027Z","iopub.execute_input":"2022-02-03T20:53:55.110375Z","iopub.status.idle":"2022-02-03T20:53:55.258218Z","shell.execute_reply.started":"2022-02-03T20:53:55.110326Z","shell.execute_reply":"2022-02-03T20:53:55.257047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:55.259734Z","iopub.execute_input":"2022-02-03T20:53:55.259991Z","iopub.status.idle":"2022-02-03T20:53:55.273798Z","shell.execute_reply.started":"2022-02-03T20:53:55.259959Z","shell.execute_reply":"2022-02-03T20:53:55.272586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"five\"></a>\n## 5. Exploratory Data Analysis (EDA)\nWithin our EDA we will use numerous visualization techniques to attempt to extract any insights from the data.\n- Movies\n- Genres\n- Cast\n- Directors\n- Plot Keywords\n- Ratings\n- Budget","metadata":{}},{"cell_type":"markdown","source":"### **Movies**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(6,10))\nsns.set(style=\"white\")\nax = sns.countplot(y=\"year\", data=movies, palette=\"Set2\", order=movies['year'].value_counts().index[0:10])\nplt.title('years most movies where released',fontsize=15)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:55.275517Z","iopub.execute_input":"2022-02-03T20:53:55.276070Z","iopub.status.idle":"2022-02-03T20:53:55.681920Z","shell.execute_reply.started":"2022-02-03T20:53:55.276025Z","shell.execute_reply":"2022-02-03T20:53:55.680991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are able to visualise that most movies have been released in 2015, followed by the year 2016 in our dataset.","metadata":{}},{"cell_type":"markdown","source":"### **Genres**","metadata":{}},{"cell_type":"code","source":"# Plot Distribution of Genres\n\nplt.subplots(figsize=(6,10))\nlist1 = []\nsns.set(style='whitegrid', palette='flare',\n        rc={'figure.figsize': (6,10)})\n\nfor i in movies['genres']:\n    list1.extend(i)\nax = pd.Series(list1).value_counts()[:10].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('flare',10))\nfor i, v in enumerate(pd.Series(list1).value_counts()[:10].sort_values(ascending=True).values): \n    ax.text(250, i-.10, v,fontsize=12,color='white',weight='bold')\nplt.title('Top Genres',fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:55.683368Z","iopub.execute_input":"2022-02-03T20:53:55.684291Z","iopub.status.idle":"2022-02-03T20:53:56.093675Z","shell.execute_reply.started":"2022-02-03T20:53:55.684241Z","shell.execute_reply":"2022-02-03T20:53:56.092806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the graph we can see that the genre 'Drama' is the most common genre for the movies in the dataset with 25606 movies followed by comedy with 16870 movies","metadata":{}},{"cell_type":"markdown","source":"### **Genres - Wordcloud**","metadata":{}},{"cell_type":"code","source":"#word cloud for genre\nall_words = \"\".join([str(i) for i in movies['genres']])\nwordcloud = WordCloud(width=1000, height=500, random_state=21, max_font_size=250, max_words=100).generate(all_words)\nplt.subplots(figsize=(12,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Popular genres',fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:56.095217Z","iopub.execute_input":"2022-02-03T20:53:56.095983Z","iopub.status.idle":"2022-02-03T20:53:57.756174Z","shell.execute_reply.started":"2022-02-03T20:53:56.095934Z","shell.execute_reply":"2022-02-03T20:53:57.755180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most frequent word is Drama and Comedy as expected from the graph above","metadata":{}},{"cell_type":"markdown","source":"### **Cast**","metadata":{}},{"cell_type":"code","source":"# Plot Distribution of Actors\n\nplt.subplots(figsize=(6,10))\nlist1=[]\nfor i in imdb_data['title_cast']:\n    list1.extend(i)\nax=pd.Series(list1).value_counts()[1:11].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('flare_r',10))\nfor i, v in enumerate(pd.Series(list1).value_counts()[1:11].sort_values(ascending=True).values): \n    ax.text(.8, i, v,fontsize=12,color='white',weight='bold')\nplt.title('Actors with highest appearance',fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:57.758050Z","iopub.execute_input":"2022-02-03T20:53:57.758636Z","iopub.status.idle":"2022-02-03T20:53:58.446919Z","shell.execute_reply.started":"2022-02-03T20:53:57.758586Z","shell.execute_reply":"2022-02-03T20:53:58.445834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the top three most popular main characters, we can observe that they are all well-known actors. People frequently prefer to watch movies based on actors they know. Movies featuring well-known actors typically receive better ratings than those starring unknown actors.","metadata":{}},{"cell_type":"markdown","source":"### **Wordloud - Cast**","metadata":{}},{"cell_type":"code","source":"#word cloud for key words that people use while searching\nall_words = ''.join([str(i) for i in imdb_data['title_cast']])\nwordcloud = WordCloud(width=1000, height=500, random_state=21, max_font_size=250, max_words=100).generate(all_words)\nplt.subplots(figsize=(10,12))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('popular cast',fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:53:58.448353Z","iopub.execute_input":"2022-02-03T20:53:58.448604Z","iopub.status.idle":"2022-02-03T20:54:05.497986Z","shell.execute_reply.started":"2022-02-03T20:53:58.448575Z","shell.execute_reply":"2022-02-03T20:54:05.496995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Directors**","metadata":{}},{"cell_type":"code","source":"# Plot Distribution of Directors\n\ndef xstr(s):\n    if s is None:\n        return ''\n    return str(s)\nimdb_data['director'] = imdb_data['director'].apply(xstr)\nplt.subplots(figsize=(6,10))\nax = imdb_data[imdb_data['director']!=''].director.value_counts()[2:12].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('flare',10))\nfor i, v in enumerate(imdb_data[imdb_data['director']!=''].director.value_counts()[2:12].sort_values(ascending=True).values): \n    ax.text(.5, i, v,fontsize=12,color='white',weight='bold')\nplt.title('Directors with highest movies',fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:05.499520Z","iopub.execute_input":"2022-02-03T20:54:05.499754Z","iopub.status.idle":"2022-02-03T20:54:05.846423Z","shell.execute_reply.started":"2022-02-03T20:54:05.499725Z","shell.execute_reply":"2022-02-03T20:54:05.845491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Among all directors in the dataset, Luc Besson is the most popular followed by Stephen King and William Shakespeare","metadata":{}},{"cell_type":"code","source":"def xstr(s):\n    if s is None:\n        return ''\n    return str(s)\nimdb_data['budget'] = imdb_data['budget'].apply(xstr)\nplt.subplots(figsize=(6,10))\nax = imdb_data[imdb_data['budget']!=''].budget.value_counts()[2:12].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('gist_earth',10))\nfor i, v in enumerate(imdb_data[imdb_data['budget']!=''].budget.value_counts()[2:12].sort_values(ascending=True).values): \n    ax.text(.5, i, v,fontsize=12,color='white',weight='bold')\nplt.title('Movie budget',fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:05.847824Z","iopub.execute_input":"2022-02-03T20:54:05.848764Z","iopub.status.idle":"2022-02-03T20:54:06.358093Z","shell.execute_reply.started":"2022-02-03T20:54:05.848709Z","shell.execute_reply":"2022-02-03T20:54:06.357048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A movie's budget plays an important role in filmmaking. With a large budget, it's easier to go all out with the film, such as using a lot of visual effects, in comparison to a low-budget picture. This is why, despite having relatively poor stories, they are more likely to appear in a cinema and obtain a larger profit.","metadata":{}},{"cell_type":"markdown","source":"### **Plot keywords**","metadata":{}},{"cell_type":"code","source":"# Create wordcloud of plot_keywords\n\ncloud = ''\nfor i in imdb_data['plot_keywords']:\n    for e in i:\n        cloud += ' '+ str(e)\n        \nwordcloud = WordCloud(width=1000, height=500, random_state=21, max_font_size=250, max_words=100).generate(cloud)\nplt.subplots(figsize=(10,7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('popular cast',fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:06.359454Z","iopub.execute_input":"2022-02-03T20:54:06.359685Z","iopub.status.idle":"2022-02-03T20:54:08.581227Z","shell.execute_reply.started":"2022-02-03T20:54:06.359657Z","shell.execute_reply":"2022-02-03T20:54:08.580273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Ratings**","metadata":{}},{"cell_type":"code","source":"print (f'Number of ratings in dataset: {train_data.shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:08.582952Z","iopub.execute_input":"2022-02-03T20:54:08.583272Z","iopub.status.idle":"2022-02-03T20:54:08.588577Z","shell.execute_reply.started":"2022-02-03T20:54:08.583235Z","shell.execute_reply":"2022-02-03T20:54:08.587424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Distribution of Ratings\n\nwith sns.axes_style('white'):\n    g = sns.factorplot('rating', data=train_data, aspect=2.0,kind='count',palette=\"rocket_r\")\n    g.set_ylabels('Total number of ratings')\n    plt.title(\"User rating distribution\",fontsize=15)\nprint (f'Average rating in dataset: {np.mean(train_data[\"rating\"])}')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:08.596219Z","iopub.execute_input":"2022-02-03T20:54:08.596505Z","iopub.status.idle":"2022-02-03T20:54:11.378768Z","shell.execute_reply.started":"2022-02-03T20:54:08.596473Z","shell.execute_reply":"2022-02-03T20:54:11.377858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There's a high percentage of movies which were rated above average i.e above 3 and a low percentage of movies which were rated below 3,seems like user realy like what they watched ","metadata":{}},{"cell_type":"code","source":"#create a dataframe to count how many times each user has rated a movie\nuser_id = pd.DataFrame(train_data.groupby('userId')['rating'].mean())\nuser_id['total number of ratings'] = pd.DataFrame(train_data.groupby('userId')['rating'].count())\nuser_id.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:11.380102Z","iopub.execute_input":"2022-02-03T20:54:11.380341Z","iopub.status.idle":"2022-02-03T20:54:12.290178Z","shell.execute_reply.started":"2022-02-03T20:54:11.380311Z","shell.execute_reply":"2022-02-03T20:54:12.289216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create new dataframe\nuser_id = pd.DataFrame(train_data.groupby('userId')['rating'].mean())\nuser_id['total number of ratings'] = pd.DataFrame(train_data.groupby('userId')['rating'].count())\n# sort dataframe by total number of ratings\nuser_id.sort_values(by=['total number of ratings'], inplace=True, ascending=False)\n# reset the index\nuser_id.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:12.291514Z","iopub.execute_input":"2022-02-03T20:54:12.291743Z","iopub.status.idle":"2022-02-03T20:54:13.204531Z","shell.execute_reply.started":"2022-02-03T20:54:12.291716Z","shell.execute_reply":"2022-02-03T20:54:13.203367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#total number of ratings per user id\nsns.barplot(y=\"total number of ratings\", x=\"userId\", data=user_id.head(10), \n order = user_id.head(10).sort_values('total number of ratings', ascending=False).userId, palette=\"rocket\")\nplt.title('Total number of ratings',fontsize=15)\nplt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:13.205788Z","iopub.execute_input":"2022-02-03T20:54:13.206108Z","iopub.status.idle":"2022-02-03T20:54:13.538157Z","shell.execute_reply.started":"2022-02-03T20:54:13.206069Z","shell.execute_reply":"2022-02-03T20:54:13.537235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"UserId 72315 has been rating most movies ,followed by UserId 80974","metadata":{}},{"cell_type":"markdown","source":"### **Joining dataFrames**\n\nThe data was provided in multiple csv files, the analysis of the data will be simpler and more efficiently carried out if the multiple files are joined to form one dataframe.","metadata":{}},{"cell_type":"code","source":"# Merge the train_data, movies & imdb_data into a joint dataframe\n\njoint_df = train_data.merge(movies,on='movieId').merge(imdb_data,on='movieId')\njoint_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:13.539403Z","iopub.execute_input":"2022-02-03T20:54:13.539642Z","iopub.status.idle":"2022-02-03T20:54:17.847565Z","shell.execute_reply.started":"2022-02-03T20:54:13.539611Z","shell.execute_reply":"2022-02-03T20:54:17.846419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove commas\njoint_df['budget'] = joint_df['budget'].astype(str).str.replace(',', '')\n\n# remove currency signs like \"$\" and \"GBP\"\njoint_df['budget'] = joint_df['budget'].str.extract('(\\d+)', expand=False)\n\n# convert the feature into a float\njoint_df['budget'] = joint_df['budget'].astype(float)\n\n# remove nan values and replacing with 0\njoint_df['budget'] = joint_df['budget'].replace(np.nan, 0)\n\n# convert the feature into an integer\njoint_df['budget'] = joint_df['budget'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:17.848939Z","iopub.execute_input":"2022-02-03T20:54:17.849238Z","iopub.status.idle":"2022-02-03T20:54:37.174812Z","shell.execute_reply.started":"2022-02-03T20:54:17.849204Z","shell.execute_reply":"2022-02-03T20:54:37.173562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Top budgets  \nplt.figure(figsize = (6,10))\nbudget=joint_df['budget'].explode()\nax=sns.countplot(x=budget, order = budget.value_counts().index[1:20], palette=\"tab20b\")\nax.set_title('Top budget',fontsize=30)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:37.176370Z","iopub.execute_input":"2022-02-03T20:54:37.176624Z","iopub.status.idle":"2022-02-03T20:54:38.147459Z","shell.execute_reply.started":"2022-02-03T20:54:37.176590Z","shell.execute_reply":"2022-02-03T20:54:38.146433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The budget of a movie is important film making. With a higher budget, it's easier to go all out with the movie, such as adding a lot of visual effects. A considerable quantity of marketing may be done for a high-budget film in contrast to a low-budget film, which is why, despite of having poor narratives, they are more likely to appear at a cinema and make profit.","metadata":{}},{"cell_type":"code","source":"def correlation_matrix( df ):\n    corr = df.corr()\n    figure , ax = plt.subplots( figsize =( 10 , 10 ) )\n    cmap = sns.diverging_palette( 220 , 20 , as_cmap = True )\n    figure = sns.heatmap(corr,cmap = cmap,square=True, cbar_kws={ 'shrink' : .9 }, ax=ax, annot = True, annot_kws = { 'fontsize' : 12 })","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:38.148872Z","iopub.execute_input":"2022-02-03T20:54:38.149112Z","iopub.status.idle":"2022-02-03T20:54:38.155602Z","shell.execute_reply.started":"2022-02-03T20:54:38.149084Z","shell.execute_reply":"2022-02-03T20:54:38.154498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select a number of features from the dataframe to make the correlation map\njoint1_df=joint_df\ncorrelation_matrix(joint_df[['userId','movieId','rating', 'timestamp', 'budget','runtime']])\nplt.title(\"Correlation matrix\")","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:38.157249Z","iopub.execute_input":"2022-02-03T20:54:38.157585Z","iopub.status.idle":"2022-02-03T20:54:42.156083Z","shell.execute_reply.started":"2022-02-03T20:54:38.157540Z","shell.execute_reply":"2022-02-03T20:54:42.155053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the correlation matrix timestamp and movieId have correlation, this might be due to the fact that movies vary in duration and do not all end at the same time. and we further obseve that there arent any significat positive correlations amongst other featuresThis might be due to the fact that movies vary in duration and do not all end at the same time.","metadata":{}},{"cell_type":"code","source":"joint1_df['runtime'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:42.157311Z","iopub.execute_input":"2022-02-03T20:54:42.157540Z","iopub.status.idle":"2022-02-03T20:54:43.769842Z","shell.execute_reply.started":"2022-02-03T20:54:42.157513Z","shell.execute_reply":"2022-02-03T20:54:43.769024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert runtime to numeric to be able to plot the graph\njoint1_df['runtime']=pd.to_numeric(joint_df['runtime'])\nplt.figure(figsize=(12,6))\nsns.distplot(joint1_df[(joint1_df['runtime'] < 300) & (joint1_df['runtime'] > 0)]['runtime'])\nplt.title(\"Runtime distribution graph\")\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:54:43.771096Z","iopub.execute_input":"2022-02-03T20:54:43.771341Z","iopub.status.idle":"2022-02-03T20:55:12.529454Z","shell.execute_reply.started":"2022-02-03T20:54:43.771312Z","shell.execute_reply":"2022-02-03T20:55:12.528624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a result, a significant number of films range between 90 and 120 minutes in length. It is roughly the greatest amount of time that the majority of viewers can sit without getting up to use the restroom o any other interruption. It is reasonable given that a significant percentage of the audience is unable to watch a three-hour film in a single sitting.","metadata":{}},{"cell_type":"code","source":"#create a new dataframe\nnew1 = pd.DataFrame(joint_df.groupby('title')['rating'].mean())\nnew1['total number of ratings'] = pd.DataFrame(joint_df.groupby('title')['rating'].count())\n# sort dataframe by total number of ratings\nnew1.sort_values(by=['total number of ratings'], inplace=True, ascending=False)\n# reset the index\nnew1.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:55:12.530693Z","iopub.execute_input":"2022-02-03T20:55:12.531067Z","iopub.status.idle":"2022-02-03T20:55:14.715035Z","shell.execute_reply.started":"2022-02-03T20:55:12.531025Z","shell.execute_reply":"2022-02-03T20:55:14.714081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(6, 10))\n\nsns.barplot(x=\"total number of ratings\", y=\"title\", data=new1.head(10), palette='crest_r')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:55:14.716499Z","iopub.execute_input":"2022-02-03T20:55:14.717000Z","iopub.status.idle":"2022-02-03T20:55:15.073377Z","shell.execute_reply.started":"2022-02-03T20:55:14.716952Z","shell.execute_reply":"2022-02-03T20:55:15.072370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph above shows most rated movies in our data set","metadata":{}},{"cell_type":"code","source":"joint_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:55:15.074549Z","iopub.execute_input":"2022-02-03T20:55:15.074783Z","iopub.status.idle":"2022-02-03T20:55:21.455528Z","shell.execute_reply.started":"2022-02-03T20:55:15.074747Z","shell.execute_reply":"2022-02-03T20:55:21.454643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Some preprocessing needed for our Content-Based Recommender System.\n- Change lists in columns to strings\n- Removing of \"noise\" in our data.\n    - Extract first two words from plot_keywords\n    - Extract first two names/surnames from title_cast","metadata":{}},{"cell_type":"code","source":"joint_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:55:21.457173Z","iopub.execute_input":"2022-02-03T20:55:21.457512Z","iopub.status.idle":"2022-02-03T20:55:21.479602Z","shell.execute_reply.started":"2022-02-03T20:55:21.457468Z","shell.execute_reply":"2022-02-03T20:55:21.478972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns with lists to strings\njoint_df['genres'] = [''.join(map(str, l)) for l in joint_df['genres']]\njoint_df['title_cast'] = [''.join(map(str, l)) for l in joint_df['title_cast']]\njoint_df['plot_keywords'] = [''.join(map(str, l)) for l in joint_df['plot_keywords']]\njoint_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:55:21.481027Z","iopub.execute_input":"2022-02-03T20:55:21.481282Z","iopub.status.idle":"2022-02-03T20:56:06.113277Z","shell.execute_reply.started":"2022-02-03T20:55:21.481249Z","shell.execute_reply":"2022-02-03T20:56:06.111860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace each plot_keywords observation, with only the first 2 words in the plot_keywords column\njoint_df['plot_keywords'] = joint_df['plot_keywords'].str.extract('(^\\w+\\W\\w+)')\n# Then replace NaN values again with nulls a computer understands\njoint_df['plot_keywords'] = joint_df['plot_keywords'].fillna('')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:56:06.115028Z","iopub.execute_input":"2022-02-03T20:56:06.115885Z","iopub.status.idle":"2022-02-03T20:56:32.241499Z","shell.execute_reply.started":"2022-02-03T20:56:06.115835Z","shell.execute_reply":"2022-02-03T20:56:32.240522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace each cast observation, with only the first 2 cast members\njoint_df['title_cast'] = joint_df['title_cast'].str.extract('(^\\w+\\W\\w+\\W\\w+\\W\\w+)')\n# Then replace NaN values again with nulls a computer understands\njoint_df['title_cast'] = joint_df['title_cast'].fillna('')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:56:32.242796Z","iopub.execute_input":"2022-02-03T20:56:32.243096Z","iopub.status.idle":"2022-02-03T20:57:02.526542Z","shell.execute_reply.started":"2022-02-03T20:56:32.243062Z","shell.execute_reply":"2022-02-03T20:57:02.525640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joint_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:02.527831Z","iopub.execute_input":"2022-02-03T20:57:02.528077Z","iopub.status.idle":"2022-02-03T20:57:02.544567Z","shell.execute_reply.started":"2022-02-03T20:57:02.528038Z","shell.execute_reply":"2022-02-03T20:57:02.543357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"six\"></a>\n## 6. Content Based Filtering\nThe content-based approach uses additional information about users and/or items. This filtering method uses item features to recommend other items similar to what the user likes and also based on their previous actions or explicit feedback.\n\nWe will use a content-based to make movie recommendations based on plot keywords, movie genres & the movie year. \nNote: Additional features such as director etc. can be added, if the computational power is avaiable.\n\n1. Create Column with the chosen combined strings.\n2. Extract original title data (no pre-processing).\n3. Use CountVectorizer to vectorize the new combined column. (CountVectorize is a method used to turn text into a numeric representation)\n4. Measure the cosine_similarity of the vectorized combined data.\n5. Create a function that uses the similarity to recommend movies based on movie input.","metadata":{}},{"cell_type":"code","source":"# Concatenate columns into single column for vectorization\njoint_df['combined'] = joint_df['year'] + joint_df['genres'] + joint_df['plot_keywords']","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:02.546118Z","iopub.execute_input":"2022-02-03T20:57:02.546472Z","iopub.status.idle":"2022-02-03T20:57:12.976448Z","shell.execute_reply.started":"2022-02-03T20:57:02.546433Z","shell.execute_reply":"2022-02-03T20:57:12.975430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create new dataframe as a copy of the old, including a merge of an original movies dataframe - for title reference.\ncontent_df = joint_df.merge(movies_og,on='movieId')\njoint_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:12.978210Z","iopub.execute_input":"2022-02-03T20:57:12.978610Z","iopub.status.idle":"2022-02-03T20:57:18.116041Z","shell.execute_reply.started":"2022-02-03T20:57:12.978546Z","shell.execute_reply":"2022-02-03T20:57:18.115113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the amount of data points to be used in the recommender system - where n = sample size\ncontent_df = content_df.sample(n=35000)\n# Set the index to movieId\ncontent_df.set_index('movieId', inplace = True)\n# Drop unnecessary columns that wont be used in the final system\ncontent_df.drop(['userId','rating','timestamp', 'genres_x','year', 'title_cast','director','runtime','budget','plot_keywords', 'genres_y', 'title_x'],axis=1,inplace=True)\n# View final dataframe for recommendation\ncontent_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:18.117574Z","iopub.execute_input":"2022-02-03T20:57:18.117830Z","iopub.status.idle":"2022-02-03T20:57:24.033326Z","shell.execute_reply.started":"2022-02-03T20:57:18.117799Z","shell.execute_reply":"2022-02-03T20:57:24.032211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combined_cleaner(df, columns):\n    \n    \"\"\" Function that takes in a dataframe & column, cleans it (as per below) and returns the cleaned dataframe\"\"\"\n    \n    for i in columns:\n        df[i] = df[i].str.replace(',', '') # remove commas\n        df[i] = df[i].str.lower() # lower case\n        df[i] = df[i].str.replace(' ', '') # remove spaces\n    return df\n\ncombined_cleaner(content_df, ['combined'])\ncontent_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:24.035175Z","iopub.execute_input":"2022-02-03T20:57:24.035514Z","iopub.status.idle":"2022-02-03T20:57:24.211267Z","shell.execute_reply.started":"2022-02-03T20:57:24.035468Z","shell.execute_reply":"2022-02-03T20:57:24.210431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:24.212269Z","iopub.execute_input":"2022-02-03T20:57:24.212890Z","iopub.status.idle":"2022-02-03T20:57:24.224475Z","shell.execute_reply.started":"2022-02-03T20:57:24.212858Z","shell.execute_reply":"2022-02-03T20:57:24.223393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save original titles\ntitles = content_df['title_y']\n\n# save indexes of current dataframe\nindices = pd.Series(content_df.index, index=content_df['title_y'])","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:24.225937Z","iopub.execute_input":"2022-02-03T20:57:24.226251Z","iopub.status.idle":"2022-02-03T20:57:24.239403Z","shell.execute_reply.started":"2022-02-03T20:57:24.226216Z","shell.execute_reply":"2022-02-03T20:57:24.238116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vectorize the final column containing chosen features\ncv = CountVectorizer()\ncv_matrix = cv.fit_transform(content_df['combined'])","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:24.240667Z","iopub.execute_input":"2022-02-03T20:57:24.241003Z","iopub.status.idle":"2022-02-03T20:57:24.479516Z","shell.execute_reply.started":"2022-02-03T20:57:24.240958Z","shell.execute_reply":"2022-02-03T20:57:24.478403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cosine Similarity Matrix\ncos_sim = cosine_similarity(cv_matrix, cv_matrix)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:24.481118Z","iopub.execute_input":"2022-02-03T20:57:24.481351Z","iopub.status.idle":"2022-02-03T20:57:28.287923Z","shell.execute_reply.started":"2022-02-03T20:57:24.481322Z","shell.execute_reply":"2022-02-03T20:57:28.286846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def content_generate_top_N_recommendations(movie_title, N=10):\n    \n    \"\"\" Function takes in a movie title('s) & N, where N is equal to the amount of recommendations you'd like to see \"\"\"\n    \n    idx=[]\n    for i in movie_title:\n        idx.append(indices[i])\n        \n    \"\"\" Function measures the similarity of the given titles with other titles\"\"\"\n    \n    sim_scores1 = list(enumerate(cos_sim[idx[0]]))\n    #sim_scores2 = list(enumerate(cos_sim[idx[1]])) # Uncomment the code to the left to add second fav movie to input\n    #sim_scores3 = list(enumerate(cos_sim[idx[2]])) # Uncomment the code to the left to add third fav movie to input\n    sim_scores = sim_scores1# + sim_scores2 + sim_scores3 # Uncomment the code to the left, depending on movie title inputs chosen\n    \n    # Select the top-N values for recommendation\n    sim_scores = sim_scores[1:N*2]\n    movie_indices = [i[0] for i in sim_scores]\n    movie_indices = np.setdiff1d(movie_indices, idx)\n          \n    # Convert the indexes back into titles \n    return titles.iloc[movie_indices[:10]]","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:28.289518Z","iopub.execute_input":"2022-02-03T20:57:28.290501Z","iopub.status.idle":"2022-02-03T20:57:28.297963Z","shell.execute_reply.started":"2022-02-03T20:57:28.290443Z","shell.execute_reply":"2022-02-03T20:57:28.297119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate N recommendations - Change value of N to change recommendations\ncontent_generate_top_N_recommendations(['Gladiator (2000)'], N=10)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:28.299288Z","iopub.execute_input":"2022-02-03T20:57:28.300115Z","iopub.status.idle":"2022-02-03T20:57:28.324089Z","shell.execute_reply.started":"2022-02-03T20:57:28.300068Z","shell.execute_reply":"2022-02-03T20:57:28.323092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"seven\"></a>\n## 7. Collaborative Filtering\nThe Collaborative filtering method for recommender systems is a method that is solely based on the past interactions that have been recorded between users and items, in order to produce new recommendations. In essence, Collaborative Filtering looks at similarities between users.\n- Matrix Factorization-based algorithms\n    - Singular Value Decomposition (SVD)\n    - Non-negative matrix factorization (NMF)\n    - Slope One\n    - Co-clustering\n- k-Nearest Neighbors (KNN)\n    - KNNBasic\n    - KNNWithMeans\n   \n#### Data Used in Collaborative Filtering:\n - train data (for model training and evaluation)\n - test data (for submission)\n \nWe will we training numerous models on a sample of the data, due to computational limitations and comparing training time & RMSE score. We will then choose the best model and move to hyperparameter tuning. Hyperparameter Tuning will be used in collaboration with Comet, where we can view past results and the hyperparameters used, then proceed to choose the best hyperparameters. Final model will be used to predict user movie-ratings.","metadata":{}},{"cell_type":"code","source":"# Loading as Surprise dataframe\ndf_train = train_data.copy()\n\n# Filter out movies that were rated less than or equal to 100\nfilter_movies = df_train['movieId'].value_counts() > 100\nfilter_movies = filter_movies[filter_movies].index.tolist()\ndf_new = df_train[(df_train['movieId'].isin(filter_movies))]\n\n# remove this code below to run on full data - Not advised, rather set n values higher.\ndf_train = df_new.sample(n=10000) \n\nreader = Reader()\n# Data selected for model training\ndata = Dataset.load_from_df(df_train[[\"userId\", \"movieId\", \"rating\"]], reader)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:28.325494Z","iopub.execute_input":"2022-02-03T20:57:28.326087Z","iopub.status.idle":"2022-02-03T20:57:30.135579Z","shell.execute_reply.started":"2022-02-03T20:57:28.326037Z","shell.execute_reply":"2022-02-03T20:57:30.134281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split Data into test & train\ntrainset, testset = train_test_split(data, test_size=0.01, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:30.136678Z","iopub.execute_input":"2022-02-03T20:57:30.136919Z","iopub.status.idle":"2022-02-03T20:57:30.173187Z","shell.execute_reply.started":"2022-02-03T20:57:30.136890Z","shell.execute_reply":"2022-02-03T20:57:30.172352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Singular Value Decomposition (SVD)\nSVD is the most common method used in collaborative filtering recommender systems, it is a linear algebra factorization technique that decomposes a matrix into three matrices. SVD shrinks space dimensions from n-dimension to k-dimension (where k<n), thus reducing the number of features.","metadata":{}},{"cell_type":"code","source":"#Save model traning time\nmodeltime = time.time()\n\n#Selecting and fitting the SVD model using the train_split set\nsvd = SVD()\nsvd.fit(trainset)\n\n#Making predictions using the fitted model\nsvd_pred = svd.test(testset) \n\n#Checking the root mean squared error to get an idea of how well the model performs\nsvd_rmse = rmse(svd_pred)\n\n#View model training time & rmse\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modeltime)))\nsvd_time = round(((time.time() - modeltime)),2)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:30.174379Z","iopub.execute_input":"2022-02-03T20:57:30.174748Z","iopub.status.idle":"2022-02-03T20:57:31.361335Z","shell.execute_reply.started":"2022-02-03T20:57:30.174717Z","shell.execute_reply":"2022-02-03T20:57:31.360389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Non-negative matrix factorization (NMF)\nNon-Negative Matrix Factorization uses techniques from multivariate analysis and linear algebra. It decomposes the data as a matrix M into the product of two lower ranking matrices W and H. The sub-matrix W contains the NMF basis; the sub-matrix H contains the associated coefficients (weights).","metadata":{}},{"cell_type":"code","source":"#Save model traning time\nmodeltime = time.time()\n\n#Selecting and fitting the NMF model using the train_split set\nnmf = NMF()\nnmf.fit(trainset)\n\n#Making predictions using the fitted model\nnmf_pred = nmf.test(testset)\n\n#Checking the root mean squared error to get an idea of how well the model performs\nnmf_rmse = rmse(nmf_pred)\n\n#View model training time & rmse\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modeltime)))\nnmf_time = round(((time.time() - modeltime)),2)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:31.362649Z","iopub.execute_input":"2022-02-03T20:57:31.362902Z","iopub.status.idle":"2022-02-03T20:57:34.431899Z","shell.execute_reply.started":"2022-02-03T20:57:31.362870Z","shell.execute_reply":"2022-02-03T20:57:34.430905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Slope One\nThe main idea of the algorithm is to create a linear relation between items preferences such as the relation F(x) = x + b. The name \"Slope One\" cames from the fact that here the \"x\" is multiplied by \"1\".","metadata":{}},{"cell_type":"code","source":"#Save model traning time\nmodeltime = time.time()\n\n#Selecting and fitting the SlopeOne model using the train_split set\nslope = SlopeOne()\nslope.fit(trainset)\n\n#Making predictions using the fitted model\nslope_pred = slope.test(testset)\n\n#Checking the root mean squared error to get an idea of how well the model performs\nslope_rmse = rmse(slope_pred)\n\n#View model training time & rmse\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modeltime)))\nslope_time = round(((time.time() - modeltime)),2)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:34.433285Z","iopub.execute_input":"2022-02-03T20:57:34.433635Z","iopub.status.idle":"2022-02-03T20:57:34.981712Z","shell.execute_reply.started":"2022-02-03T20:57:34.433598Z","shell.execute_reply":"2022-02-03T20:57:34.980649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Co-clustering\nCo-clustering (or Biclustering) is a term in data mining that relates to a simultaneous clustering of the rows and columns of a matrix. Where classical clustering methods assume that a membership of an object (in a group of objects) depends solely on its similarity to other objects of the same type (same entity type), co-clustering can be seen as a method of co-grouping two types of entities simultaneously, based on similarity of their pairwise interactions.","metadata":{}},{"cell_type":"code","source":"#Save model traning time\nmodeltime = time.time()\n\n#Selecting and fitting the CoClustering model using the train_split set\ncc = CoClustering()\ncc.fit(trainset)\n\n#Making predictions using the fitted model\ncc_pred = cc.test(testset)\n\n#Checking the root mean squared error to get an idea of how well the model performs\ncc_rmse = rmse(cc_pred)\n\n#View model training time & rmse\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modeltime)))\ncc_time = round(((time.time() - modeltime)),2)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:34.983142Z","iopub.execute_input":"2022-02-03T20:57:34.983403Z","iopub.status.idle":"2022-02-03T20:57:37.068403Z","shell.execute_reply.started":"2022-02-03T20:57:34.983372Z","shell.execute_reply":"2022-02-03T20:57:37.067333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### KNNBasic\nKNNBasic is a basic collaborative filtering algorithm and is often used as a benchmark for more complex classifiers like the Support Vector Machines (SVM) and the Artificial Neural Networks (ANN).","metadata":{}},{"cell_type":"code","source":"#Save model traning time\nmodeltime = time.time()\n\n#Selecting and fitting the KNNBasic model using the train_split set\nknnb = KNNBasic()\nknnb.fit(trainset)\n\n#Making predictions using the fitted model\nknnb_pred = knnb.test(testset) \n\n#Checking the root mean squared error to get an idea of how well the model performs\nknnb_rmse = rmse(knnb_pred)\n\n#View model training time & rmse\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modeltime)))\nknnb_time = round(((time.time() - modeltime)),2)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:37.069821Z","iopub.execute_input":"2022-02-03T20:57:37.071231Z","iopub.status.idle":"2022-02-03T20:57:40.299161Z","shell.execute_reply.started":"2022-02-03T20:57:37.071176Z","shell.execute_reply":"2022-02-03T20:57:40.298091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### KNNWithZMeans\nKNNWithZScore is a basic collaborative filtering algorithm, taking into account the z-score normalization of each user.","metadata":{}},{"cell_type":"code","source":"#Save model traning time\nmodeltime = time.time()\n\n#Selecting and fitting the KNNWithMeans model using the train_split set\nknnm = KNNWithMeans()\nknnm.fit(trainset)\n\n#Making predictions using the fitted model\nknnm_pred = knnm.test(testset) \n\n#Checking the root mean squared error to get an idea of how well the model performs\nknnm_rmse = rmse(knnm_pred)\n\n#View model training time & rmse\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modeltime)))\nknnm_time = round(((time.time() - modeltime)),2)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:40.301244Z","iopub.execute_input":"2022-02-03T20:57:40.301590Z","iopub.status.idle":"2022-02-03T20:57:43.791376Z","shell.execute_reply.started":"2022-02-03T20:57:40.301541Z","shell.execute_reply":"2022-02-03T20:57:43.790405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"eight\"></a>\n## 8. Evaluating Model Performances\n - Select best model for Hyperparameter Tuning and Submission","metadata":{}},{"cell_type":"code","source":"# Compare RMSE Between Models\n\nfig,axis = plt.subplots(figsize=(16, 4))\nrmse_y = ['SVD','NMF','Slope One', 'Co-Clustering', 'KNNBasic', 'KNNWithMeans']\nrmse_x = [svd_rmse,nmf_rmse,slope_rmse, cc_rmse, knnb_rmse, knnm_rmse]\nax = sns.barplot(y=rmse_y, x=rmse_x,palette='rocket_r')\nplt.title('Model RMSE Compared',fontsize=15)\nplt.xlabel('RMSE', size=13)\nplt.yticks(size=12)\nplt.xticks(size=12)\nfor i in ax.patches:\n    ax.text(i.get_x() + i.get_height()*1.5, i.get_y() + i.get_height()-0.1, round(i.get_width(),2), fontsize=12, ha=\"left\", va='bottom')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:43.793063Z","iopub.execute_input":"2022-02-03T20:57:43.793378Z","iopub.status.idle":"2022-02-03T20:57:44.101464Z","shell.execute_reply.started":"2022-02-03T20:57:43.793308Z","shell.execute_reply":"2022-02-03T20:57:44.100369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare Training Times Between Models\n\nfig,axis = plt.subplots(figsize=(16, 4))\nrmse_y = ['SVD','NMF','Slope One', 'Co-Clustering', 'KNNBasic', 'KNNWithMeans']\nrmse_x = [svd_time,nmf_time,slope_time, cc_time, knnb_time, knnm_time]\nax = sns.barplot(y=rmse_y, x=rmse_x,palette='rocket_r')\nplt.title('Model Training Time Compared',fontsize=15)\nplt.xlabel('Training Time', size=13)\nplt.yticks(size=12)\nplt.xticks(size=12)\nfor i in ax.patches:\n    ax.text(i.get_x() + i.get_height()*5, i.get_y() + i.get_height()-0.2, round(i.get_width(),2), fontsize=12, ha=\"left\", va='bottom')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:44.103090Z","iopub.execute_input":"2022-02-03T20:57:44.103384Z","iopub.status.idle":"2022-02-03T20:57:44.417188Z","shell.execute_reply.started":"2022-02-03T20:57:44.103348Z","shell.execute_reply":"2022-02-03T20:57:44.416092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"nine\"></a>\n## 9. Hyperparameter Tuning\n - Hyperparameter Tuning of Best performing Model - SVD\n - In collaboration with Comet","metadata":{}},{"cell_type":"code","source":"df_train = train_data.copy()\n\n# Use full data for final training and test data\n# Remove the line of code below to hyperparameter tune on all data.\ndf_train = df_train.sample(n=10000)\n\ntrain_data = Dataset.load_from_df(df_train[[\"userId\", \"movieId\", \"rating\"]], reader = Reader())\ntrainset = train_data.build_full_trainset()\n\n# Select hyperparameters to be included in the GridSearch to find optimal.\nparam_grid = {'n_epochs': [10],\n'n_factors': [400],\n'lr_all': [0.001, 0.003, 0.004, 0.005],\n'reg_all': [0.005, 0.01, 0.02, 0.4, 0.5, 0.8]}\n\n# Apply GridSearchCV & fit to chosen data\nsvd = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs = -1)\nsvd.fit(train_data)\n\n# Prints best hyperparameters\nprint(\"Best Parameters\", svd.best_params['rmse'])","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:57:44.418661Z","iopub.execute_input":"2022-02-03T20:57:44.418908Z","iopub.status.idle":"2022-02-03T20:58:45.976093Z","shell.execute_reply.started":"2022-02-03T20:57:44.418878Z","shell.execute_reply":"2022-02-03T20:58:45.975315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Log best parameters & RMSE score to Comet\nparams = svd.best_params['rmse']\nrmse = svd.best_score['rmse']\n\n\n# Uncomment the below to save results to comet\n\"\"\"experiment.log_parameters(params)\nexperiment.log_metric('rmse', rmse)\n\n# End the experiment\nexperiment.end()\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:45.977326Z","iopub.execute_input":"2022-02-03T20:58:45.977556Z","iopub.status.idle":"2022-02-03T20:58:45.985146Z","shell.execute_reply.started":"2022-02-03T20:58:45.977528Z","shell.execute_reply":"2022-02-03T20:58:45.984155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"ten\"></a>\n## 10. Conculsion\n- Recommender System\n    - Content-Based Filtering\n    - Collaborative Filtering\n- Performances of all Models\n    - RMSE\n    - Training Time\n- Best Performing Model\n    - SVD","metadata":{}},{"cell_type":"markdown","source":"Firstly, we used **Content-Based filtering** to give a user a list of recommendations based on the movie input data. The recommender uses the similarity between movies to recommend a movie the user might like. Next we decided to use **Collaborative Filtering** to create a recommender model able to accurately predicting how a user will rate a movie they have not yet viewed, based on their historical preferences, as per the initial problem statement. With Collaborative Filtering we used numerous models and **compared RMSE and the training times**, but in the end, **Singular Value Decomposition (SVD)** outperformed the rest. We then trained SVD on all the data, moved to hyperparameter tuning, which we used in collaboration with Comet thus enabling us to do numerous parameter experiments and choose the best possible hyperpameters, which gave us a model which is able to accuratly predict movie ratings.\n\n**Best Performing Parameters** {'n_epochs': 55, 'n_factors': 150, 'lr_all': 0.0065, 'reg_all': 0.01}\n\n**Final Kaggle Score** 0.79842","metadata":{}},{"cell_type":"markdown","source":"<a id=\"eleven\"></a>\n## 11. Submission\n- Use trained model to predict Ratings in the Test Data","metadata":{}},{"cell_type":"code","source":"# Make Predictions\nratings_predictions=[svd.predict(row.userId, row.movieId) for _,row in test_data.iterrows()]","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:45.986519Z","iopub.execute_input":"2022-02-03T20:58:45.987463Z","iopub.status.idle":"2022-02-03T20:58:46.175882Z","shell.execute_reply.started":"2022-02-03T20:58:45.987414Z","shell.execute_reply":"2022-02-03T20:58:46.174604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred=pd.DataFrame(ratings_predictions)\ndf_pred=df_pred.rename(columns={'uid':'userId', 'iid':'movieId','est':'rating'})\ndf_pred.drop(['r_ui','details'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:46.177149Z","iopub.status.idle":"2022-02-03T20:58:46.177519Z","shell.execute_reply.started":"2022-02-03T20:58:46.177344Z","shell.execute_reply":"2022-02-03T20:58:46.177363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred['Id']=df_pred.apply(lambda x:'%s_%s' % (x['userId'],x['movieId']),axis=1)\ndf_pred['Id']=df_pred.apply(lambda x:'%s_%s' % (x['userId'],x['movieId']),axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:46.178543Z","iopub.status.idle":"2022-02-03T20:58:46.178839Z","shell.execute_reply.started":"2022-02-03T20:58:46.178680Z","shell.execute_reply":"2022-02-03T20:58:46.178696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:46.180360Z","iopub.status.idle":"2022-02-03T20:58:46.180662Z","shell.execute_reply.started":"2022-02-03T20:58:46.180504Z","shell.execute_reply":"2022-02-03T20:58:46.180520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred.drop(['userId', 'movieId'], inplace=True, axis= 1)\ndf_pred = df_pred[['Id', 'rating']]","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:46.181663Z","iopub.status.idle":"2022-02-03T20:58:46.181965Z","shell.execute_reply.started":"2022-02-03T20:58:46.181807Z","shell.execute_reply":"2022-02-03T20:58:46.181823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Export the submission to CSV\ndf_pred.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:58:46.182946Z","iopub.status.idle":"2022-02-03T20:58:46.183301Z","shell.execute_reply.started":"2022-02-03T20:58:46.183125Z","shell.execute_reply":"2022-02-03T20:58:46.183143Z"},"trusted":true},"execution_count":null,"outputs":[]}]}